{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8141b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m166 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add ipykernel\n",
    "!uv add langchain\n",
    "!uv add langgraph\n",
    "!uv add \"psycopg[binary,pool]\"\n",
    "!uv add langgraph-checkpoint-postgres\n",
    "!uv add langgraph-checkpoint\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a1d7c",
   "metadata": {},
   "source": [
    "# çŸ­æœŸè®°å¿†è¯¦è§£\n",
    "\n",
    "InMemorySaverå†…å­˜ä¼šè¯ä¸´æ—¶å­˜å‚¨\n",
    "\n",
    "å¯¹äºŽå¼€å‘ã€åŽŸåž‹è®¾è®¡å’Œæµ‹è¯•é˜¶æ®µï¼Œæœ€ç®€å•å¿«æ·çš„æ–¹å¼æ˜¯ä½¿ç”¨InMemorySaverã€‚å®ƒå°†æ‰€æœ‰çš„å¯¹è¯çŠ¶æ€å­˜å‚¨åœ¨å†…å­˜ä¸­çš„ä¸€ä¸ªPythonå­—å…¸é‡Œã€‚\n",
    "\n",
    "## 1.è®¾ç½®è®°å¿†ç®¡ç†æ£€æŸ¥ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218642cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import os\n",
    "\n",
    "# åˆå§‹åŒ–æ£€æŸ¥ç‚¹ä¿å­˜å™¨\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1a6fc",
   "metadata": {},
   "source": [
    "## 2.å®šä¹‰å¤§æ¨¡åž‹å¹¶åˆ›å»ºagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7412bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL=os.getenv(\"OPENAI_BASE_URL\")\n",
    "TOKEN=os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\",\n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    # ä¼ å…¥æ£€æŸ¥ç‚¹ï¼Œæ˜¯å°†æŒä¹…åŒ–èƒ½åŠ›â€œæ³¨å…¥â€å›¾çš„å…³é”®æ­¥éª¤ã€‚ç¼–è¯‘åŽçš„graphå¯¹è±¡çŽ°åœ¨å…·å¤‡äº†çŠ¶æ€ç®¡ç†çš„èƒ½åŠ›ã€‚\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5807f3",
   "metadata": {},
   "source": [
    "## 3.çŸ­æœŸè®°å¿†-å†…å­˜åŽç«¯\n",
    "\n",
    "çŸ­æœŸè®°å¿†ä¸Žçº¿ç¨‹ç›¸å…³ï¼Œåœ¨å¯¹è¯æ—¶ï¼Œéœ€è¦åœ¨é…ç½®ä¸­ä¼ å…¥thread_idã€‚é€šè¿‡ä¸Šé¢çš„ç»“æžœæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬ä¼ å…¥ç›¸åŒçš„thread_idæ—¶ï¼Œagentå°±å¯ä»¥è®°ä½ç”¨æˆ·çš„åå­—ï¼Œç„¶è€Œå½“æˆ‘ä»¬æ›´æ¢thread_idæ—¶ï¼Œagentå°±ä¸è®°å¾—ç”¨æˆ·çš„åå­—äº†ã€‚\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒInMemorySaverå°†æ‰€æœ‰çŠ¶æ€éƒ½ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œä¸€æ—¦ç¨‹åºç»ˆæ­¢ï¼Œé‚£ä¹ˆæ‰€æœ‰å¯¹è¯åŽ†å²éƒ½ä¼šæ¶ˆå¤±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732c412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread1_bot_answerï¼šä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼ŸðŸ˜Š\n",
      "------------çº¿ç¨‹1------------------\n",
      "thread1_bot_answerï¼šå½“ç„¶è®°å¾—ï¼ä½ å« Adaï¼ðŸ˜Š æœ‰ä»€ä¹ˆéœ€è¦å¸®å¿™çš„å—ï¼Ÿ\n",
      "------------çº¿ç¨‹2------------------\n",
      "thread2_bot_answerï¼šä½ å¥½ï¼å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ— æ³•è®°ä½æˆ–å­˜å‚¨ä»»ä½•ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½ çš„åå­—ã€‚å¦‚æžœä½ æ„¿æ„ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ä½ çš„åå­—ï¼Œæˆ‘ä¼šåœ¨å½“å‰å¯¹è¯ä¸­ä½¿ç”¨å®ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¿€æ´»è®°å¿†æœºåˆ¶çš„æ ¸å¿ƒã€‚å¦‚æžœæ²¡æœ‰æä¾›thread_idï¼Œæ¯æ¬¡invokeè°ƒç”¨éƒ½å°†æ˜¯æ— çŠ¶æ€çš„ï¼Œ\n",
    "# åªè¦ä½¿ç”¨ç›¸åŒçš„thread_idï¼ŒLangGraphå°±ä¼šåœ¨å¤šæ¬¡è°ƒç”¨ä¹‹é—´ç»´æŒå¯¹è¯çŠ¶æ€\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(f\"thread1_bot_answerï¼š{response['messages'][-1].content}\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print('------------çº¿ç¨‹1------------------')\n",
    "print(f\"thread1_bot_answerï¼š{response['messages'][-1].content}\")\n",
    "\n",
    "new_config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]},\n",
    "    new_config\n",
    ")\n",
    "print('------------çº¿ç¨‹2------------------')\n",
    "print(f\"thread2_bot_answerï¼š{response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818851a",
   "metadata": {},
   "source": [
    "## æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨\n",
    "\n",
    "å¯ä»¥å‘çŽ°ï¼Œä¸Šé¢ä¸€å°èŠ‚çš„ä»£ç åœ¨åº”ç”¨ç¨‹åºç»“æŸåŽå†å¯åŠ¨ï¼Œè®°å¿†å°±åˆæ¶ˆå¤±äº†ã€‚è¿™æ˜¯å› ä¸ºInMemorySaverä»…ä»…æ˜¯æŠŠè®°å¿†ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œåº”ç”¨ç¨‹åºç»“æŸåŽé‡Šæ”¾å†…å­˜è®°å¿†å°±æ¶ˆå¤±äº†ã€‚åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­å¸¸å¸¸ä½¿ç”¨æ•°æ®åº“æ”¯æŒçš„æ£€æŸ¥ç‚¹è®°å½•å™¨æŒä¹…åŒ–ä¿å­˜è®°å¿†ï¼Œä»¥ä¿è¯æ•°æ®çš„å¯é æ€§å’ŒæœåŠ¡çš„è¿žç»­æ€§ã€‚\n",
    "è¿™é‡Œæˆ‘ä»¬ä»¥postgresæ•°æ®åº“ä¸ºä¾‹æ¥è¯´æ˜Žï¼Œæ€Žä¹ˆæŒä¹…åŒ–åœ°ä¿å­˜è®°å¿†æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abb3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ï¼ðŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ\n",
      "å½“ç„¶è®°å¾—ï¼ä½ å« Adaï¼Œå¯¹å§ï¼ŸðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "BASE_URL=os.getenv(\"OPENAI_BASE_URL\")\n",
    "TOKEN=os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "DB_URI = \"postgresql://postgres:password@localhost:5432/agent-memory?sslmode=disable\"\n",
    "\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup()  # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¿…é¡»è¦ setup()\n",
    "    \n",
    "    def call_model(state: MessagesState):\n",
    "        response = model.invoke(state[\"messages\"])\n",
    "        return {\"messages\": response}\n",
    "    \n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    "    \n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    config = { \"configurable\": {\"thread_id\": \"1\"} }\n",
    "\n",
    "    response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼\"}]}, config)\n",
    "\n",
    "    print(response['messages'][-1].content)\n",
    "\n",
    "    response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]}, config)\n",
    "\n",
    "    print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd181bd",
   "metadata": {},
   "source": [
    "è¿è¡Œä¸€æ¬¡ä¸Šè¿°ä»£ç åŽï¼Œå…³é—­åº”ç”¨ç¨‹åºåŽé‡å¯ï¼Œå†æ¬¡è¿è¡Œä¸Šè¿°ä»£ç ã€‚\n",
    "å¯ä»¥çœ‹åˆ°ï¼Œè®°å¿†å·²ç»è¢«ä¿å­˜äº†ã€‚æˆ‘ä»¬æ£€æŸ¥æ•°æ®åº“å¯ä»¥å‘çŽ°ï¼Œpostgresæ•°æ®åº“ä¸­å‡ºçŽ°äº†å››ä¸ªè¡¨ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b9cc5",
   "metadata": {},
   "source": [
    "```\n",
    "public | checkpoint_blobs      | table | postgres\n",
    "public | checkpoint_migrations | table | postgres\n",
    "public | checkpoint_writes     | table | postgres\n",
    "public | checkpoints           | table | postgres\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687973a",
   "metadata": {},
   "source": [
    "ä¸Šè¿°è¡¨ä¸­ï¼Œcheckpointsè¡¨æ˜¯â€çŠ¶æ€å¿«ç…§â€œè¡¨ï¼Œæ¯å½“ç¨‹åºæ‰§è¡Œä¸€ä¸ªstepæ—¶ï¼Œå®ƒå°±ä¼šåœ¨è¿™å¼ è¡¨ä¸­åˆ›å»ºä¸€æ¡æ–°è®°å½•ï¼Œè¿™æ¡è®°å½•å°±æ˜¯ä¸€ä¸ªæ£€æŸ¥ç‚¹çš„å¿«ç…§ã€‚\n",
    "æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥åˆ†æžæ¯ä¸€åˆ—çš„å«ä¹‰ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a8c27",
   "metadata": {},
   "source": [
    "| åˆ—å                  | å«ä¹‰                                             | ä¸¾ä¾‹è¯´æ˜Ž                                                 |\n",
    "|----------------------|-------------------------------------------------|---------------------------------------------------------|\n",
    "| thread_id            | çº¿ç¨‹ID                                          | ä¸Šè¿°è¡¨ä¸­, æ‰€æœ‰ thread_id éƒ½ä¸º 1, è¡¨ç¤ºè¿™äº›è®°å½•éƒ½å±žäºŽåŒä¸€ä¸ªä¼šè¯æµ |\n",
    "| checkpoint_ns        | æ£€æŸ¥ç‚¹å‘½åç©ºé—´(Namespace), ç”¨äºŽå¯¹æ£€æŸ¥ç‚¹è¿›è¡Œåˆ†ç»„æˆ–åˆ†ç±» |                                                         |\n",
    "| checkpoint_id        | æ£€æŸ¥ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦, è¯¥è®°å½•çš„ä¸»é”®                    |                                                         |\n",
    "| parent_checkpoint_id | çˆ¶æ£€æŸ¥ç‚¹çš„ ID, å®ƒå°†æ£€æŸ¥ç‚¹é“¾æŽ¥èµ·æ¥                   | ç¬¬ä¸€æ¡ parent_checkpoint_id æ˜¯ç©ºçš„, ä»£è¡¨çš„æ˜¯æ•´ä¸ªæµç¨‹çš„èµ·ç‚¹    |\n",
    "| checkpoint_id        | æ ¸å¿ƒçŠ¶æ€æ•°æ®, æ˜¯ä¸€ä¸ª JSON å¯¹è±¡                     | tsä»£è¡¨æ—¶é—´æˆ³, channel_values ä»£è¡¨é€šé“å€¼, å¯ä»¥ç†è§£ä¸ºå·¥ä½œæµä¸­çš„å˜é‡å€¼     |\n",
    "| metadata             | è¯¥æ£€æŸ¥ç‚¹æœ¬èº«çš„å…ƒæ•°æ®                               | stepè¡¨ç¤ºè¿™æ˜¯å·¥ä½œæµçš„ç¬¬å‡ æ­¥, source è¡¨æ¥æº, input æŒ‡å¤–éƒ¨è¾“å…¥ | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5dc4d",
   "metadata": {},
   "source": [
    "é™¤äº†PostgreSQLä¹‹å¤–ï¼ŒLangGraphè¿˜æ”¯æŒMongoDBã€Redisç­‰æ•°æ®åº“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b516ab7",
   "metadata": {},
   "source": [
    "ç†è§£äº†ä¸Šé¢checkpointsè¡¨åŽï¼Œé‚£ä¹ˆä¸ç¦ä¼šé—®ï¼ŒçœŸæ­£çš„æ¶ˆæ¯å†…å®¹è¢«å­˜åˆ°äº†å“ªé‡Œå‘¢ï¼ŸçœŸæ­£çš„æ¶ˆæ¯å†…å®¹å­˜å‚¨åœ¨checkpoint_writesè¡¨ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d29f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from typing import TypedDict\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "# å­å›¾\n",
    "def subgraph_node_1(state: State):\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "subgraph_builder = StateGraph(State)\n",
    "subgraph_builder.add_node(subgraph_node_1)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node_1\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# çˆ¶å›¾\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", subgraph)\n",
    "builder.add_edge(START, \"node_1\")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b491f",
   "metadata": {},
   "source": [
    "å¦‚æžœå­å›¾å¸Œæœ›ä½¿ç”¨è‡ªå·±çš„çŸ­æœŸè®°å¿†ï¼Œé‚£ä¹ˆéœ€è¦åœ¨ç¼–è¯‘å­å›¾æ—¶ï¼Œæ˜¾ç¤ºä¼ å…¥å­å›¾çš„æ£€æŸ¥ç‚¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2007934",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_builder = StateGraph(...)\n",
    "subgraph = subgraph_builder.compile(checkpointer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1a519",
   "metadata": {},
   "source": [
    "## åœ¨å·¥å…·ä¸­è¯»å–çŠ¶æ€\n",
    "\n",
    "LangGraphå…è®¸å·¥å…·ç›´æŽ¥è®¿é—®å’Œè¯»å–å½“å‰çš„å›¾çŠ¶æ€ï¼Œä½¿å…¶å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚\n",
    "æ ¸å¿ƒæœºåˆ¶ï¼šstate: Annotated[CustomState, InjectedState]ï¼ŒInjectedStateçš„ä½œç”¨æ˜¯åœ¨è°ƒç”¨è¿™ä¸ªå·¥å…·æ—¶ï¼Œå°†å½“å‰çš„å®Œæ•´çŠ¶æ€å¯¹è±¡ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ä¼ é€’åˆ°å·¥å…·ä¸­ï¼Œä½¿å¾—è¿™ä¸ªå·¥å…·èƒ½æ ¹æ®å½“å‰çŠ¶æ€æ¥æ‰§è¡Œæ›´æ™ºèƒ½çš„æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54864af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯', additional_kwargs={}, response_metadata={}, id='811288c4-ab87-4c68-8324-440c9412594b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MRzAlx4rr3rF5AjqyZH6WvKu', 'function': {'arguments': '{}', 'name': 'get_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 39, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3b1593f-17ed-40b2-9276-b75f1b9e1f85-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'call_MRzAlx4rr3rF5AjqyZH6WvKu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 39, 'output_tokens': 12, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='ada', name='get_user_info', id='deb5297f-673f-454c-b26c-e4bd982f9621', tool_call_id='call_MRzAlx4rr3rF5AjqyZH6WvKu'),\n",
       "  AIMessage(content='ç”¨æˆ·ä¿¡æ¯å·²æŸ¥è¯¢æˆåŠŸã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 60, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ca97b84-50d3-4a18-9f35-4533fae4b507-0', usage_metadata={'input_tokens': 60, 'output_tokens': 8, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'user_id': 'user_ada'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "BASE_URL=os.getenv(\"OPENAI_BASE_URL\")\n",
    "TOKEN=os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "def get_user_info(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    return \"ada\" if state[\"user_id\"] == \"user_ada\" else \"Unknown\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": \"æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\", \"user_id\": \"user_ada\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c6ad6",
   "metadata": {},
   "source": [
    "## åœ¨å·¥å…·ä¸­å†™å…¥çŠ¶æ€\n",
    "\n",
    "å¦‚æžœè¦åœ¨å·¥å…·æ‰§è¡ŒæœŸé—´ä¿®æ”¹å›¾çš„è®°å¿†ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æŽ¥ä»Žå·¥å…·è¿”å›žçŠ¶æ€æ›´æ–°ã€‚è¿™å¯¹äºŽæŒä¹…åŒ–ä¸­é—´ç»“æžœã€ä¼ é€’ä¿¡æ¯ç»™åŽç»­å·¥å…·ç­‰éžå¸¸æœ‰ç”¨ã€‚\n",
    "æ ¸å¿ƒæœºåˆ¶ï¼šå·¥å…·è¿”å›žCommandå¯¹è±¡ã€‚æ­¤æ—¶ï¼ŒLangGraphä¼šå°†å…¶è¿”å›žå€¼è§£é‡Šä¸ºå¯¹çŠ¶æ€çš„ç›´æŽ¥ä¿®æ”¹æŒ‡ä»¤ã€‚Command(update={...})ä¸­çš„å­—å…¸å®šä¹‰äº†è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µåŠå…¶æ–°å€¼ã€‚è¿™å…è®¸å·¥å…·åœ¨å®Œæˆå…¶ä¸»è¦ä»»åŠ¡çš„åŒæ—¶ï¼Œå°†ç»“æžœå†™å›žæ™ºèƒ½ä½“çš„çŸ­æœŸè®°å¿†ä¸­ï¼Œä»Žè€Œå½±å“åŽç»­çš„å†³ç­–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0eb2876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='å‘ç”¨æˆ·æ‰“æ‹›å‘¼', additional_kwargs={}, response_metadata={}, id='c6546062-e36c-463d-8c06-6c156ca59616'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aQZ5xfhNO7ZbdMeCSsFalXg4', 'function': {'arguments': '{}', 'name': 'greet', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 64, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e5f3bb4f-0548-47e7-a454-897eb6ef8dac-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_aQZ5xfhNO7ZbdMeCSsFalXg4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 64, 'output_tokens': 11, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Error: 1 validation error for greet\\nstate.user_name\\n  Field required [type=missing, input_value={'messages': [HumanMessag..., 'remaining_steps': 24}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\\n Please fix your mistakes.\", name='greet', id='b79a3a0a-f476-445f-ae38-69da68d41abf', tool_call_id='call_aQZ5xfhNO7ZbdMeCSsFalXg4', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_obsmkwrzmvXrtqHm2dpxoGfP', 'function': {'arguments': '{}', 'name': 'update_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 149, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b0bed6d5-25c3-4d0c-8d82-39f6431a6e35-0', tool_calls=[{'name': 'update_user_info', 'args': {}, 'id': 'call_obsmkwrzmvXrtqHm2dpxoGfP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 12, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='æˆåŠŸæŸ¥è¯¢åˆ°ç”¨æˆ·ä¿¡æ¯', name='update_user_info', id='3b5adab5-6942-4abd-b105-ca48aaf87e39', tool_call_id='call_obsmkwrzmvXrtqHm2dpxoGfP'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p916oubzHGzwJlE5oyRJjLjE', 'function': {'arguments': '{}', 'name': 'greet', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 174, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a21a17ed-bfcb-4840-a27d-68cc9fdcca40-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_p916oubzHGzwJlE5oyRJjLjE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 11, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='ä½ å¥½ adaï¼', name='greet', id='4348ff23-6097-4729-936a-616ed371f252', tool_call_id='call_p916oubzHGzwJlE5oyRJjLjE'),\n",
       "  AIMessage(content='ä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 195, 'total_tokens': 208, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-de4a3d21-e9a0-4073-965f-974e11f1332c-0', usage_metadata={'input_tokens': 195, 'output_tokens': 13, 'total_tokens': 208, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'user_name': 'ada'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.types import Command\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_name: str\n",
    "def update_user_info(\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    config: RunnableConfig\n",
    ") -> Command:\n",
    "    \"\"\"æŸ¥è¯¢å¹¶æ›´æ–°ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    name = \"ada\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={\"user_name\": name, \"messages\": [ToolMessage(\"æˆåŠŸæŸ¥è¯¢åˆ°ç”¨æˆ·ä¿¡æ¯\", tool_call_id=tool_call_id)]})\n",
    "\n",
    "def greet(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"æ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯åŽï¼Œä½¿ç”¨æ­¤æ–¹å¼å‘ç”¨æˆ·é—®å¥½ã€‚\"\"\"\n",
    "    user_name = state[\"user_name\"]\n",
    "    return f\"ä½ å¥½ {user_name}ï¼\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å‘ç”¨æˆ·æ‰“æ‹›å‘¼\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"user_123\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf1555",
   "metadata": {},
   "source": [
    "## é•¿æœŸè®°å¿†è¯¦è§£\n",
    "\n",
    "LangGraphä¸­çš„é•¿æœŸè®°å¿†å…è®¸ç³»ç»Ÿåœ¨ä¸åŒå¯¹è¯ä¸­ä¿ç•™ä¿¡æ¯ï¼Œæ˜¯è·¨å¯¹è¯çº¿ç¨‹å…±äº«çš„ï¼Œå¯ä»¥åœ¨ä»»ä½•æ—¶é—´ã€ä»»ä½•çº¿ç¨‹ä¸­è¢«å›žå¿†ã€‚ä¸ŽçŸ­æœŸè®°å¿†ä¸åŒï¼Œé•¿æœŸè®°å¿†ä¿å­˜åœ¨è‡ªå®šä¹‰çš„å‘½åç©ºé—´ä¸­ï¼Œæ¯ä¸ªè®°å¿†éƒ½ç»„ç»‡åœ¨ä¸€ä¸ªè‡ªå®šä¹‰çš„namespaceå’Œä¸€ä¸ªå”¯ä¸€çš„keyä¸‹ã€‚\n",
    "è®°å¿†å­˜å‚¨ï¼šLangGraphå°†é•¿æœŸè®°å¿†å­˜å‚¨ä¸ºJSONæ–‡æ¡£ï¼Œä½¿ç”¨Storeè¿›è¡Œç®¡ç†ï¼Œå…è®¸å­˜å‚¨ç»“æž„åŒ–å’Œéžç»“æž„åŒ–çš„æ•°æ®ã€‚\n",
    "è®°å¿†æ›´æ–°æ—¶æœºï¼š\n",
    "â— çƒ­è·¯å¾„ï¼ˆHot Pathï¼‰ï¼šåœ¨åº”ç”¨ç¨‹åºé€»è¾‘è¿è¡Œæ—¶å®žæ—¶åˆ›å»ºè®°å¿†ï¼ˆstore.put()ï¼‰ï¼Œä¼˜ç‚¹æ˜¯å®žæ—¶æ›´æ–°ï¼Œä½†å¯èƒ½å¢žåŠ ç¨‹åºå¤æ‚æ€§ã€å»¶è¿Ÿç­‰é—®é¢˜ã€‚\n",
    "â— åŽå°ï¼ˆBackgroundï¼‰ï¼šä½œä¸ºå•ç‹¬çš„å¼‚æ­¥ä»»åŠ¡åˆ›å»ºè®°å¿†ï¼ˆstore.put()ï¼‰ï¼Œä¼˜ç‚¹æ˜¯é¿å…ä¸»åº”ç”¨å»¶è¿Ÿã€é€»è¾‘åˆ†ç¦»ï¼Œéš¾ç‚¹åœ¨äºŽç¡®å®šæ›´æ–°é¢‘çŽ‡å’Œè§¦å‘æ—¶æœºã€‚\n",
    "è®°å¿†æ£€ç´¢ï¼š\n",
    "â— store.get()ï¼šæ ¹æ®å‘½åç©ºé—´å’Œé”®ç²¾ç¡®èŽ·å–è®°å¿†ã€‚\n",
    "â— store.search()ï¼šåœ¨æŒ‡å®šå‘½åç©ºé—´å†…å®žçŽ°çµæ´»è®°å¿†æ£€ç´¢ï¼Œä¸ä½†å¯ä»¥é€šè¿‡å‘½åç©ºé—´å’Œæ ‡è¯†ç¬¦ï¼Œæ›´å¯ä»¥é€šè¿‡è¯­ä¹‰æ£€ç´¢åˆ°è®°å¿†å†…å®¹ã€‚é€šå¸¸éœ€è¦Storeé…ç½®ä¸€ä¸ªembedæ¥æ”¯æŒè¯­ä¹‰æœç´¢ã€‚\n",
    "è®°å¿†çš„åº”ç”¨ï¼š\n",
    "â— è¯­ä¹‰è®°å¿†ï¼šå­˜å‚¨äº‹å®žå’Œæ¦‚å¿µã€‚åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§æƒ…å†µï¼šProfileï¼šå°†å…³äºŽç”¨æˆ·ã€ç»„ç»‡æˆ–ä»£ç†è‡ªèº«çš„ç‰¹å®šä¿¡æ¯å­˜å‚¨ä¸ºä¸€ä¸ªæŒç»­æ›´æ–°çš„JSONæ–‡æ¡£ï¼Œéœ€è¦æ¨¡åž‹æ¥ç”Ÿæˆæ–°çš„Profileæˆ–æ›´æ–°å·²æœ‰JSONæ¡£æ¡ˆï¼›Collectionï¼šå°†è®°å¿†å­˜å‚¨ä¸ºä¸€ç»„ç‹¬ç«‹çš„æ–‡æ¡£ï¼Œæ˜“äºŽç”Ÿæˆï¼Œä½†æ£€ç´¢å’Œæ›´æ–°è¾ƒä¸ºå¤æ‚ï¼Œä¸”å¯èƒ½éš¾ä»¥æ•èŽ·è®°å¿†é—´çš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚åœ¨åº”ç”¨æ—¶ï¼Œå¯ä»¥å°†æ£€ç´¢åˆ°çš„è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æˆ–ç³»ç»ŸæŒ‡ä»¤çš„ä¸€éƒ¨åˆ†ä¼ é€’ç»™LLMï¼Œç”¨äºŽä¸ªæ€§åŒ–å“åº”å’Œå›žç­”äº‹å®žæ€§é—®é¢˜ã€‚\n",
    "â— æƒ…æ™¯è®°å¿†ï¼šå­˜å‚¨è¿‡åŽ»çš„äº‹ä»¶æˆ–è¡Œä¸ºç»éªŒã€‚é€šå¸¸é€šè¿‡few-shot example promptæ¥å®žçŽ°ï¼Œä»¥æŒ‡å¯¼æ¨¡åž‹å®Œæˆä»»åŠ¡ã€‚\n",
    "â— ç¨‹åºè®°å¿†ï¼šå­˜å‚¨æ‰§è¡Œä»»åŠ¡çš„è§„åˆ™æˆ–æŒ‡ä»¤ã€‚é€šå¸¸é€šè¿‡ä¿®æ”¹ä»£ç è‡ªèº«çš„promptæ¥å®žçŽ°ï¼Œå°†å…¶åº”ç”¨äºŽLLMã€‚\n",
    "InMemoryStore\n",
    "\n",
    "ä¸ŽCheckpointerç±»ä¼¼ï¼ŒInMemoryStoreç”¨äºŽå¿«é€Ÿå¼€å‘å’ŒåŽŸåž‹éªŒè¯ã€‚å®ƒå°†æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3833e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='å¸®æˆ‘æŸ¥æ‰¾é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯', additional_kwargs={}, response_metadata={}, id='1f3a2201-9b56-4084-9ac9-211f039bf87e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DkywsciacCOBvcLmAJG579bc', 'function': {'arguments': '{}', 'name': 'get_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 63, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-21751cac-9477-4807-8ccc-6f75d3bb4484-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'call_DkywsciacCOBvcLmAJG579bc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 12, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'name': 'ada', 'language': 'ä¸­æ–‡'}\", name='get_user_info', id='36ac949a-f694-4453-8cdd-b0b2350c8633', tool_call_id='call_DkywsciacCOBvcLmAJG579bc'), AIMessage(content='æˆ‘æŸ¥æ‰¾åˆ°é•¿æœŸè®°å¿†ä¸­çš„ç”¨æˆ·ä¿¡æ¯å¦‚ä¸‹ï¼š\\n\\n- ç”¨æˆ·åï¼šAda\\n- ä½¿ç”¨è¯­è¨€ï¼šä¸­æ–‡', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 95, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-225a580c-0755-4440-9678-54b2bb5d70ee-0', usage_metadata={'input_tokens': 95, 'output_tokens': 24, 'total_tokens': 119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.config import get_store\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "store = InMemoryStore()\n",
    "BASE_URL=os.getenv(\"OPENAI_BASE_URL\")\n",
    "TOKEN=os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "store.put(\n",
    "    (\"users\",),                         # å‘½åç©ºé—´ï¼šå…ƒç»„ç±»åž‹ï¼Œç±»æ¯”æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶å¤¹ï¼Œæ”¯æŒåˆ†å±‚ç»„ç»‡ç»“æž„\n",
    "    \"user_123\",                         # é”®: å­—ç¬¦ä¸²ï¼Œæ˜¯å‘½åç©ºé—´å†…çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä¸€èˆ¬æŽ¨èä½¿ç”¨uuidåº“ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦\n",
    "    {\"name\": \"ada\", \"language\": \"ä¸­æ–‡\"}  # å€¼ï¼šPythonå­—å…¸ç±»åž‹ï¼Œæ¯”å¦‚ä¿å­˜å…¬å…±è§’è‰²èµ„æ–™æ—¶å¯ä»¥æ˜¯åŒ…å«å§“åã€åå¥½ç­‰é”®å€¼å¯¹çš„å­—å…¸\n",
    ")\n",
    "\n",
    "def get_user_info(config: RunnableConfig) -> str:\n",
    "    \"\"\"æŸ¥æ‰¾ç”¨æˆ·ä¿¡æ¯çš„å‡½æ•°ï¼Œå¯ä»¥æŸ¥çœ‹é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    store = get_store()  # èŽ·å–ä¸Šä¸‹æ–‡ä¸­å¯ç”¨çš„storeå®žä¾‹\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    user_info = store.get((\"users\",), user_id)  # è¾“å…¥å‘½åç©ºé—´å’Œé”®è¿›è¡Œç²¾ç¡®æŸ¥è¯¢\n",
    "    return str(user_info.value) if user_info else\"Unknown user\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    # ä¼ å…¥store\n",
    "    store=store\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¸®æˆ‘æŸ¥æ‰¾é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"user_123\"}}\n",
    ")\n",
    "\n",
    "print(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccd4f3",
   "metadata": {},
   "source": [
    "## æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨\n",
    "\n",
    "ä¸ºäº†è®©è®°å¿†çœŸæ­£â€é•¿æœŸâ€œï¼Œç”Ÿäº§çŽ¯å¢ƒå¿…é¡»ä½¿ç”¨æ•°æ®åº“æ”¯æŒçš„Storeï¼ŒLangGraphç›®å‰ä¸»è¦æ”¯æŒPostgresStoreå’ŒRedisStoreã€‚æˆ‘ä»¬ä»¥PostgresStoreä¸ºä¾‹æ¥è¿›è¡Œè¯´æ˜Žã€‚\\\n",
    "æŽ¥ä¸‹æ¥è¿›è¡Œç¤ºä¾‹è¯´æ˜Žã€‚æ•´ä½“è¿‡ç¨‹ä¸ŽCheckpointerç±»ä¼¼ï¼Œå…³é”®åŒºåˆ«åœ¨äºŽStoreæ˜¯æ€Žæ ·åœ¨èŠ‚ç‚¹å†…éƒ¨è¢«è®¿é—®å’Œä½¿ç”¨çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87946df",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "the connection is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œå‘Šè¯‰agentç”¨æˆ·çš„åå­—\u001b[39;00m\n\u001b[1;32m     59\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[0;32m---> 61\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mä½ å¥½ï¼Œæˆ‘å«adaï¼è®°ä½è¿™ä¸ªåå­—å‘¦~\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# ç¬¬äºŒæ¬¡å¯¹è¯ï¼Œæ–°çº¿ç¨‹ï¼Œè¯¢é—®agentè®°ä¸è®°å¾—ç”¨æˆ·çš„åå­—\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2844\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[0m\n\u001b[1;32m   2841\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2842\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2845\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2846\u001b[0m     config,\n\u001b[1;32m   2847\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2848\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   2850\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   2851\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2852\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2853\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2855\u001b[0m ):\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2857\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2467\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2466\u001b[0m     config[CONF][CONFIG_KEY_CHECKPOINT_DURING] \u001b[38;5;241m=\u001b[39m checkpoint_during\n\u001b[0;32m-> 2467\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2469\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   2470\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   2471\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   2472\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   2473\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   2474\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   2475\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   2476\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2477\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   2478\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   2479\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   2480\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   2481\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   2482\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m config[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_CHECKPOINT_DURING, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2485\u001b[0m     trigger_to_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_to_nodes,\n\u001b[1;32m   2486\u001b[0m     migrate_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_checkpoint,\n\u001b[1;32m   2487\u001b[0m     retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2488\u001b[0m     cache_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_policy,\n\u001b[1;32m   2489\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   2491\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   2492\u001b[0m         submit\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2493\u001b[0m             CONFIG_KEY_RUNNER_SUBMIT, weakref\u001b[38;5;241m.\u001b[39mWeakMethod(loop\u001b[38;5;241m.\u001b[39msubmit)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2496\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[1;32m   2497\u001b[0m     )\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/langgraph/pregel/loop.py:1003\u001b[0m, in \u001b[0;36mSyncPregelLoop.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer:\n\u001b[0;32m-> 1003\u001b[0m         saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m         saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/langgraph/checkpoint/postgres/__init__.py:229\u001b[0m, in \u001b[0;36mPostgresSaver.get_tuple\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    226\u001b[0m     args \u001b[38;5;241m=\u001b[39m (thread_id, checkpoint_ns)\n\u001b[1;32m    227\u001b[0m     where \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWHERE thread_id = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m AND checkpoint_ns = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ORDER BY checkpoint_id DESC LIMIT 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m    230\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSELECT_SQL \u001b[38;5;241m+\u001b[39m where,\n\u001b[1;32m    232\u001b[0m         args,\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m     value \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchone()\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.19-macos-aarch64-none/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/langgraph/checkpoint/postgres/__init__.py:430\u001b[0m, in \u001b[0;36mPostgresSaver._cursor\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m cur\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_row\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cur\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/psycopg/connection.py:213\u001b[0m, in \u001b[0;36mConnection.cursor\u001b[0;34m(self, name, binary, row_factory, scrollable, withhold)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcursor\u001b[39m(\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    203\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     withhold: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Cursor[Any] \u001b[38;5;241m|\u001b[39m ServerCursor[Any]:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    Return a new `Cursor` to send commands and queries to the connection.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_connection_ok\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row_factory:\n\u001b[1;32m    216\u001b[0m         row_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_factory\n",
      "File \u001b[0;32m~/opt/learning/cs/Python/learning-langchain/.venv/lib/python3.10/site-packages/psycopg/_connection_base.py:532\u001b[0m, in \u001b[0;36mBaseConnection._check_connection_ok\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpgconn\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m BAD:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mOperationalError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe connection is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mInterfaceError(\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot execute operations: the connection is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpgconn\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m )\n",
      "\u001b[0;31mOperationalError\u001b[0m: the connection is closed"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "BASE_URL=os.getenv(\"OPENAI_BASE_URL\")\n",
    "TOKEN=os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "DB_URI = \"postgresql://postgres:password@localhost:5432/agent-memory?sslmode=disable\"\n",
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    store.setup()  # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¿…é¡»è¦setup()\n",
    "#checkpointer.setup()\n",
    "    \n",
    "# å£°æ˜Žstoreå‚æ•°\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig, \n",
    "    *,\n",
    "    store: BaseStore,  # åœ¨èŠ‚ç‚¹ä¸­è®¿é—®storeçš„æ ‡å‡†æ–¹å¼ï¼Œéœ€è¦åœ¨å‡½æ•°ç­¾åä¸Šï¼ŒåŠ ä¸€ä¸ªstore\n",
    "    ):\n",
    "    # ä»Žstoreä¸­è¯»å–è®°å¿†\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "    system_msg = f\"ä½ æ˜¯ä¸€ä¸ªä¸Žäººç±»äº¤æµçš„å°åŠ©æ‰‹ï¼Œç”¨æˆ·ä¿¡æ¯: {info}\"\n",
    "\n",
    "    # å‘storeä¸­å†™å…¥è®°å¿†\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"è®°ä½\" in last_message.content.lower(): memory = \"ç”¨æˆ·åå­—æ˜¯ada\"\n",
    "    store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "    response = model.invoke([{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "    \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer, store=store)  # agentåŒæ—¶é…å¤‡äº†çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†èƒ½åŠ›\n",
    "    \n",
    "# ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œå‘Šè¯‰agentç”¨æˆ·çš„åå­—\n",
    "config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"1\"}}\n",
    "\n",
    "response = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼è®°ä½è¿™ä¸ªåå­—å‘¦~\"}]}, \n",
    "    config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# ç¬¬äºŒæ¬¡å¯¹è¯ï¼Œæ–°çº¿ç¨‹ï¼Œè¯¢é—®agentè®°ä¸è®°å¾—ç”¨æˆ·çš„åå­—\n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": \"1\"}}\n",
    "\n",
    "response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆ?\"}]}, config)\n",
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
