{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8141b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m165 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m200 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m166 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add ipykernel\n",
    "!uv add langchain\n",
    "!uv add langgraph\n",
    "!uv add \"psycopg[binary,pool]\"\n",
    "!uv add langgraph-checkpoint-postgres\n",
    "!uv add langgraph-checkpoint\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a1d7c",
   "metadata": {},
   "source": [
    "# çŸ­æœŸè®°å¿†è¯¦è§£\n",
    "\n",
    "InMemorySaverå†…å­˜ä¼šè¯ä¸´æ—¶å­˜å‚¨\n",
    "\n",
    "å¯¹äºå¼€å‘ã€åŸå‹è®¾è®¡å’Œæµ‹è¯•é˜¶æ®µï¼Œæœ€ç®€å•å¿«æ·çš„æ–¹å¼æ˜¯ä½¿ç”¨InMemorySaverã€‚å®ƒå°†æ‰€æœ‰çš„å¯¹è¯çŠ¶æ€å­˜å‚¨åœ¨å†…å­˜ä¸­çš„ä¸€ä¸ªPythonå­—å…¸é‡Œã€‚\n",
    "\n",
    "## 1.è®¾ç½®è®°å¿†ç®¡ç†æ£€æŸ¥ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218642cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# åˆå§‹åŒ–æ£€æŸ¥ç‚¹ä¿å­˜å™¨\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1a6fc",
   "metadata": {},
   "source": [
    "## 2.å®šä¹‰å¤§æ¨¡å‹å¹¶åˆ›å»ºagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7412bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL=\"https://api.apiyi.com/v1\"\n",
    "TOKEN=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\"\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\",\n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    # ä¼ å…¥æ£€æŸ¥ç‚¹ï¼Œæ˜¯å°†æŒä¹…åŒ–èƒ½åŠ›â€œæ³¨å…¥â€å›¾çš„å…³é”®æ­¥éª¤ã€‚ç¼–è¯‘åçš„graphå¯¹è±¡ç°åœ¨å…·å¤‡äº†çŠ¶æ€ç®¡ç†çš„èƒ½åŠ›ã€‚\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5807f3",
   "metadata": {},
   "source": [
    "## 3.çŸ­æœŸè®°å¿†-å†…å­˜åç«¯\n",
    "\n",
    "çŸ­æœŸè®°å¿†ä¸çº¿ç¨‹ç›¸å…³ï¼Œåœ¨å¯¹è¯æ—¶ï¼Œéœ€è¦åœ¨é…ç½®ä¸­ä¼ å…¥thread_idã€‚é€šè¿‡ä¸Šé¢çš„ç»“æœæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬ä¼ å…¥ç›¸åŒçš„thread_idæ—¶ï¼Œagentå°±å¯ä»¥è®°ä½ç”¨æˆ·çš„åå­—ï¼Œç„¶è€Œå½“æˆ‘ä»¬æ›´æ¢thread_idæ—¶ï¼Œagentå°±ä¸è®°å¾—ç”¨æˆ·çš„åå­—äº†ã€‚\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒInMemorySaverå°†æ‰€æœ‰çŠ¶æ€éƒ½ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œä¸€æ—¦ç¨‹åºç»ˆæ­¢ï¼Œé‚£ä¹ˆæ‰€æœ‰å¯¹è¯å†å²éƒ½ä¼šæ¶ˆå¤±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732c412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread1_bot_answerï¼šä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼ŸğŸ˜Š\n",
      "------------çº¿ç¨‹1------------------\n",
      "thread1_bot_answerï¼šå½“ç„¶è®°å¾—ï¼ä½ å« Adaï¼ğŸ˜Š æœ‰ä»€ä¹ˆéœ€è¦å¸®å¿™çš„å—ï¼Ÿ\n",
      "------------çº¿ç¨‹2------------------\n",
      "thread2_bot_answerï¼šä½ å¥½ï¼å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ— æ³•è®°ä½æˆ–å­˜å‚¨ä»»ä½•ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½ çš„åå­—ã€‚å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ä½ çš„åå­—ï¼Œæˆ‘ä¼šåœ¨å½“å‰å¯¹è¯ä¸­ä½¿ç”¨å®ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¿€æ´»è®°å¿†æœºåˆ¶çš„æ ¸å¿ƒã€‚å¦‚æœæ²¡æœ‰æä¾›thread_idï¼Œæ¯æ¬¡invokeè°ƒç”¨éƒ½å°†æ˜¯æ— çŠ¶æ€çš„ï¼Œ\n",
    "# åªè¦ä½¿ç”¨ç›¸åŒçš„thread_idï¼ŒLangGraphå°±ä¼šåœ¨å¤šæ¬¡è°ƒç”¨ä¹‹é—´ç»´æŒå¯¹è¯çŠ¶æ€\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(f\"thread1_bot_answerï¼š{response['messages'][-1].content}\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print('------------çº¿ç¨‹1------------------')\n",
    "print(f\"thread1_bot_answerï¼š{response['messages'][-1].content}\")\n",
    "\n",
    "new_config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]},\n",
    "    new_config\n",
    ")\n",
    "print('------------çº¿ç¨‹2------------------')\n",
    "print(f\"thread2_bot_answerï¼š{response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818851a",
   "metadata": {},
   "source": [
    "## æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨\n",
    "\n",
    "å¯ä»¥å‘ç°ï¼Œä¸Šé¢ä¸€å°èŠ‚çš„ä»£ç åœ¨åº”ç”¨ç¨‹åºç»“æŸåå†å¯åŠ¨ï¼Œè®°å¿†å°±åˆæ¶ˆå¤±äº†ã€‚è¿™æ˜¯å› ä¸ºInMemorySaverä»…ä»…æ˜¯æŠŠè®°å¿†ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œåº”ç”¨ç¨‹åºç»“æŸåé‡Šæ”¾å†…å­˜è®°å¿†å°±æ¶ˆå¤±äº†ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¸¸å¸¸ä½¿ç”¨æ•°æ®åº“æ”¯æŒçš„æ£€æŸ¥ç‚¹è®°å½•å™¨æŒä¹…åŒ–ä¿å­˜è®°å¿†ï¼Œä»¥ä¿è¯æ•°æ®çš„å¯é æ€§å’ŒæœåŠ¡çš„è¿ç»­æ€§ã€‚\n",
    "è¿™é‡Œæˆ‘ä»¬ä»¥postgresæ•°æ®åº“ä¸ºä¾‹æ¥è¯´æ˜ï¼Œæ€ä¹ˆæŒä¹…åŒ–åœ°ä¿å­˜è®°å¿†æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78abb3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ï¼ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ\n",
      "å½“ç„¶è®°å¾—ï¼ä½ å« Adaï¼Œå¯¹å§ï¼ŸğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "BASE_URL=\"https://api.apiyi.com/v1\"\n",
    "TOKEN=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\"\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "DB_URI = \"postgresql://postgres:password@localhost:5432/agent-memory?sslmode=disable\"\n",
    "\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup()  # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¿…é¡»è¦ setup()\n",
    "    \n",
    "    def call_model(state: MessagesState):\n",
    "        response = model.invoke(state[\"messages\"])\n",
    "        return {\"messages\": response}\n",
    "    \n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    "    \n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    config = { \"configurable\": {\"thread_id\": \"1\"} }\n",
    "\n",
    "    response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼\"}]}, config)\n",
    "\n",
    "    print(response['messages'][-1].content)\n",
    "\n",
    "    response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ\"}]}, config)\n",
    "\n",
    "    print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd181bd",
   "metadata": {},
   "source": [
    "è¿è¡Œä¸€æ¬¡ä¸Šè¿°ä»£ç åï¼Œå…³é—­åº”ç”¨ç¨‹åºåé‡å¯ï¼Œå†æ¬¡è¿è¡Œä¸Šè¿°ä»£ç ã€‚\n",
    "å¯ä»¥çœ‹åˆ°ï¼Œè®°å¿†å·²ç»è¢«ä¿å­˜äº†ã€‚æˆ‘ä»¬æ£€æŸ¥æ•°æ®åº“å¯ä»¥å‘ç°ï¼Œpostgresæ•°æ®åº“ä¸­å‡ºç°äº†å››ä¸ªè¡¨ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b9cc5",
   "metadata": {},
   "source": [
    "```\n",
    "public | checkpoint_blobs      | table | postgres\n",
    "public | checkpoint_migrations | table | postgres\n",
    "public | checkpoint_writes     | table | postgres\n",
    "public | checkpoints           | table | postgres\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687973a",
   "metadata": {},
   "source": [
    "ä¸Šè¿°è¡¨ä¸­ï¼Œcheckpointsè¡¨æ˜¯â€çŠ¶æ€å¿«ç…§â€œè¡¨ï¼Œæ¯å½“ç¨‹åºæ‰§è¡Œä¸€ä¸ªstepæ—¶ï¼Œå®ƒå°±ä¼šåœ¨è¿™å¼ è¡¨ä¸­åˆ›å»ºä¸€æ¡æ–°è®°å½•ï¼Œè¿™æ¡è®°å½•å°±æ˜¯ä¸€ä¸ªæ£€æŸ¥ç‚¹çš„å¿«ç…§ã€‚\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥åˆ†ææ¯ä¸€åˆ—çš„å«ä¹‰ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a8c27",
   "metadata": {},
   "source": [
    "| åˆ—å                  | å«ä¹‰                                             | ä¸¾ä¾‹è¯´æ˜                                                 |\n",
    "|----------------------|-------------------------------------------------|---------------------------------------------------------|\n",
    "| thread_id            | çº¿ç¨‹ID                                          | ä¸Šè¿°è¡¨ä¸­, æ‰€æœ‰ thread_id éƒ½ä¸º 1, è¡¨ç¤ºè¿™äº›è®°å½•éƒ½å±äºåŒä¸€ä¸ªä¼šè¯æµ |\n",
    "| checkpoint_ns        | æ£€æŸ¥ç‚¹å‘½åç©ºé—´(Namespace), ç”¨äºå¯¹æ£€æŸ¥ç‚¹è¿›è¡Œåˆ†ç»„æˆ–åˆ†ç±» |                                                         |\n",
    "| checkpoint_id        | æ£€æŸ¥ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦, è¯¥è®°å½•çš„ä¸»é”®                    |                                                         |\n",
    "| parent_checkpoint_id | çˆ¶æ£€æŸ¥ç‚¹çš„ ID, å®ƒå°†æ£€æŸ¥ç‚¹é“¾æ¥èµ·æ¥                   | ç¬¬ä¸€æ¡ parent_checkpoint_id æ˜¯ç©ºçš„, ä»£è¡¨çš„æ˜¯æ•´ä¸ªæµç¨‹çš„èµ·ç‚¹    |\n",
    "| checkpoint_id        | æ ¸å¿ƒçŠ¶æ€æ•°æ®, æ˜¯ä¸€ä¸ª JSON å¯¹è±¡                     | tsä»£è¡¨æ—¶é—´æˆ³, channel_values ä»£è¡¨é€šé“å€¼, å¯ä»¥ç†è§£ä¸ºå·¥ä½œæµä¸­çš„å˜é‡å€¼     |\n",
    "| metadata             | è¯¥æ£€æŸ¥ç‚¹æœ¬èº«çš„å…ƒæ•°æ®                               | stepè¡¨ç¤ºè¿™æ˜¯å·¥ä½œæµçš„ç¬¬å‡ æ­¥, source è¡¨æ¥æº, input æŒ‡å¤–éƒ¨è¾“å…¥ | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5dc4d",
   "metadata": {},
   "source": [
    "é™¤äº†PostgreSQLä¹‹å¤–ï¼ŒLangGraphè¿˜æ”¯æŒMongoDBã€Redisç­‰æ•°æ®åº“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b516ab7",
   "metadata": {},
   "source": [
    "ç†è§£äº†ä¸Šé¢checkpointsè¡¨åï¼Œé‚£ä¹ˆä¸ç¦ä¼šé—®ï¼ŒçœŸæ­£çš„æ¶ˆæ¯å†…å®¹è¢«å­˜åˆ°äº†å“ªé‡Œå‘¢ï¼ŸçœŸæ­£çš„æ¶ˆæ¯å†…å®¹å­˜å‚¨åœ¨checkpoint_writesè¡¨ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d29f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from typing import TypedDict\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "# å­å›¾\n",
    "def subgraph_node_1(state: State):\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "subgraph_builder = StateGraph(State)\n",
    "subgraph_builder.add_node(subgraph_node_1)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node_1\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# çˆ¶å›¾\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", subgraph)\n",
    "builder.add_edge(START, \"node_1\")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b491f",
   "metadata": {},
   "source": [
    "å¦‚æœå­å›¾å¸Œæœ›ä½¿ç”¨è‡ªå·±çš„çŸ­æœŸè®°å¿†ï¼Œé‚£ä¹ˆéœ€è¦åœ¨ç¼–è¯‘å­å›¾æ—¶ï¼Œæ˜¾ç¤ºä¼ å…¥å­å›¾çš„æ£€æŸ¥ç‚¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2007934",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_builder = StateGraph(...)\n",
    "subgraph = subgraph_builder.compile(checkpointer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1a519",
   "metadata": {},
   "source": [
    "## åœ¨å·¥å…·ä¸­è¯»å–çŠ¶æ€\n",
    "\n",
    "LangGraphå…è®¸å·¥å…·ç›´æ¥è®¿é—®å’Œè¯»å–å½“å‰çš„å›¾çŠ¶æ€ï¼Œä½¿å…¶å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚\n",
    "æ ¸å¿ƒæœºåˆ¶ï¼šstate: Annotated[CustomState, InjectedState]ï¼ŒInjectedStateçš„ä½œç”¨æ˜¯åœ¨è°ƒç”¨è¿™ä¸ªå·¥å…·æ—¶ï¼Œå°†å½“å‰çš„å®Œæ•´çŠ¶æ€å¯¹è±¡ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ä¼ é€’åˆ°å·¥å…·ä¸­ï¼Œä½¿å¾—è¿™ä¸ªå·¥å…·èƒ½æ ¹æ®å½“å‰çŠ¶æ€æ¥æ‰§è¡Œæ›´æ™ºèƒ½çš„æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54864af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯', additional_kwargs={}, response_metadata={}, id='811288c4-ab87-4c68-8324-440c9412594b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MRzAlx4rr3rF5AjqyZH6WvKu', 'function': {'arguments': '{}', 'name': 'get_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 39, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3b1593f-17ed-40b2-9276-b75f1b9e1f85-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'call_MRzAlx4rr3rF5AjqyZH6WvKu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 39, 'output_tokens': 12, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='ada', name='get_user_info', id='deb5297f-673f-454c-b26c-e4bd982f9621', tool_call_id='call_MRzAlx4rr3rF5AjqyZH6WvKu'),\n",
       "  AIMessage(content='ç”¨æˆ·ä¿¡æ¯å·²æŸ¥è¯¢æˆåŠŸã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 60, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ca97b84-50d3-4a18-9f35-4533fae4b507-0', usage_metadata={'input_tokens': 60, 'output_tokens': 8, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'user_id': 'user_ada'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "BASE_URL=\"https://api.apiyi.com/v1\"\n",
    "TOKEN=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\"\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "def get_user_info(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    return \"ada\" if state[\"user_id\"] == \"user_ada\" else \"Unknown\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": \"æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\", \"user_id\": \"user_ada\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c6ad6",
   "metadata": {},
   "source": [
    "## åœ¨å·¥å…·ä¸­å†™å…¥çŠ¶æ€\n",
    "\n",
    "å¦‚æœè¦åœ¨å·¥å…·æ‰§è¡ŒæœŸé—´ä¿®æ”¹å›¾çš„è®°å¿†ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æ¥ä»å·¥å…·è¿”å›çŠ¶æ€æ›´æ–°ã€‚è¿™å¯¹äºæŒä¹…åŒ–ä¸­é—´ç»“æœã€ä¼ é€’ä¿¡æ¯ç»™åç»­å·¥å…·ç­‰éå¸¸æœ‰ç”¨ã€‚\n",
    "æ ¸å¿ƒæœºåˆ¶ï¼šå·¥å…·è¿”å›Commandå¯¹è±¡ã€‚æ­¤æ—¶ï¼ŒLangGraphä¼šå°†å…¶è¿”å›å€¼è§£é‡Šä¸ºå¯¹çŠ¶æ€çš„ç›´æ¥ä¿®æ”¹æŒ‡ä»¤ã€‚Command(update={...})ä¸­çš„å­—å…¸å®šä¹‰äº†è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µåŠå…¶æ–°å€¼ã€‚è¿™å…è®¸å·¥å…·åœ¨å®Œæˆå…¶ä¸»è¦ä»»åŠ¡çš„åŒæ—¶ï¼Œå°†ç»“æœå†™å›æ™ºèƒ½ä½“çš„çŸ­æœŸè®°å¿†ä¸­ï¼Œä»è€Œå½±å“åç»­çš„å†³ç­–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0eb2876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='å‘ç”¨æˆ·æ‰“æ‹›å‘¼', additional_kwargs={}, response_metadata={}, id='c6546062-e36c-463d-8c06-6c156ca59616'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aQZ5xfhNO7ZbdMeCSsFalXg4', 'function': {'arguments': '{}', 'name': 'greet', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 64, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e5f3bb4f-0548-47e7-a454-897eb6ef8dac-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_aQZ5xfhNO7ZbdMeCSsFalXg4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 64, 'output_tokens': 11, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Error: 1 validation error for greet\\nstate.user_name\\n  Field required [type=missing, input_value={'messages': [HumanMessag..., 'remaining_steps': 24}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\\n Please fix your mistakes.\", name='greet', id='b79a3a0a-f476-445f-ae38-69da68d41abf', tool_call_id='call_aQZ5xfhNO7ZbdMeCSsFalXg4', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_obsmkwrzmvXrtqHm2dpxoGfP', 'function': {'arguments': '{}', 'name': 'update_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 149, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b0bed6d5-25c3-4d0c-8d82-39f6431a6e35-0', tool_calls=[{'name': 'update_user_info', 'args': {}, 'id': 'call_obsmkwrzmvXrtqHm2dpxoGfP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 12, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='æˆåŠŸæŸ¥è¯¢åˆ°ç”¨æˆ·ä¿¡æ¯', name='update_user_info', id='3b5adab5-6942-4abd-b105-ca48aaf87e39', tool_call_id='call_obsmkwrzmvXrtqHm2dpxoGfP'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p916oubzHGzwJlE5oyRJjLjE', 'function': {'arguments': '{}', 'name': 'greet', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 174, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a21a17ed-bfcb-4840-a27d-68cc9fdcca40-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_p916oubzHGzwJlE5oyRJjLjE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 11, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='ä½ å¥½ adaï¼', name='greet', id='4348ff23-6097-4729-936a-616ed371f252', tool_call_id='call_p916oubzHGzwJlE5oyRJjLjE'),\n",
       "  AIMessage(content='ä½ å¥½ï¼ŒAdaï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 195, 'total_tokens': 208, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-de4a3d21-e9a0-4073-965f-974e11f1332c-0', usage_metadata={'input_tokens': 195, 'output_tokens': 13, 'total_tokens': 208, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'user_name': 'ada'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.types import Command\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_name: str\n",
    "def update_user_info(\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    config: RunnableConfig\n",
    ") -> Command:\n",
    "    \"\"\"æŸ¥è¯¢å¹¶æ›´æ–°ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    name = \"ada\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={\"user_name\": name, \"messages\": [ToolMessage(\"æˆåŠŸæŸ¥è¯¢åˆ°ç”¨æˆ·ä¿¡æ¯\", tool_call_id=tool_call_id)]})\n",
    "\n",
    "def greet(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"æ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯åï¼Œä½¿ç”¨æ­¤æ–¹å¼å‘ç”¨æˆ·é—®å¥½ã€‚\"\"\"\n",
    "    user_name = state[\"user_name\"]\n",
    "    return f\"ä½ å¥½ {user_name}ï¼\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å‘ç”¨æˆ·æ‰“æ‹›å‘¼\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"user_123\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf1555",
   "metadata": {},
   "source": [
    "## é•¿æœŸè®°å¿†è¯¦è§£\n",
    "\n",
    "LangGraphä¸­çš„é•¿æœŸè®°å¿†å…è®¸ç³»ç»Ÿåœ¨ä¸åŒå¯¹è¯ä¸­ä¿ç•™ä¿¡æ¯ï¼Œæ˜¯è·¨å¯¹è¯çº¿ç¨‹å…±äº«çš„ï¼Œå¯ä»¥åœ¨ä»»ä½•æ—¶é—´ã€ä»»ä½•çº¿ç¨‹ä¸­è¢«å›å¿†ã€‚ä¸çŸ­æœŸè®°å¿†ä¸åŒï¼Œé•¿æœŸè®°å¿†ä¿å­˜åœ¨è‡ªå®šä¹‰çš„å‘½åç©ºé—´ä¸­ï¼Œæ¯ä¸ªè®°å¿†éƒ½ç»„ç»‡åœ¨ä¸€ä¸ªè‡ªå®šä¹‰çš„namespaceå’Œä¸€ä¸ªå”¯ä¸€çš„keyä¸‹ã€‚\n",
    "è®°å¿†å­˜å‚¨ï¼šLangGraphå°†é•¿æœŸè®°å¿†å­˜å‚¨ä¸ºJSONæ–‡æ¡£ï¼Œä½¿ç”¨Storeè¿›è¡Œç®¡ç†ï¼Œå…è®¸å­˜å‚¨ç»“æ„åŒ–å’Œéç»“æ„åŒ–çš„æ•°æ®ã€‚\n",
    "è®°å¿†æ›´æ–°æ—¶æœºï¼š\n",
    "â— çƒ­è·¯å¾„ï¼ˆHot Pathï¼‰ï¼šåœ¨åº”ç”¨ç¨‹åºé€»è¾‘è¿è¡Œæ—¶å®æ—¶åˆ›å»ºè®°å¿†ï¼ˆstore.put()ï¼‰ï¼Œä¼˜ç‚¹æ˜¯å®æ—¶æ›´æ–°ï¼Œä½†å¯èƒ½å¢åŠ ç¨‹åºå¤æ‚æ€§ã€å»¶è¿Ÿç­‰é—®é¢˜ã€‚\n",
    "â— åå°ï¼ˆBackgroundï¼‰ï¼šä½œä¸ºå•ç‹¬çš„å¼‚æ­¥ä»»åŠ¡åˆ›å»ºè®°å¿†ï¼ˆstore.put()ï¼‰ï¼Œä¼˜ç‚¹æ˜¯é¿å…ä¸»åº”ç”¨å»¶è¿Ÿã€é€»è¾‘åˆ†ç¦»ï¼Œéš¾ç‚¹åœ¨äºç¡®å®šæ›´æ–°é¢‘ç‡å’Œè§¦å‘æ—¶æœºã€‚\n",
    "è®°å¿†æ£€ç´¢ï¼š\n",
    "â— store.get()ï¼šæ ¹æ®å‘½åç©ºé—´å’Œé”®ç²¾ç¡®è·å–è®°å¿†ã€‚\n",
    "â— store.search()ï¼šåœ¨æŒ‡å®šå‘½åç©ºé—´å†…å®ç°çµæ´»è®°å¿†æ£€ç´¢ï¼Œä¸ä½†å¯ä»¥é€šè¿‡å‘½åç©ºé—´å’Œæ ‡è¯†ç¬¦ï¼Œæ›´å¯ä»¥é€šè¿‡è¯­ä¹‰æ£€ç´¢åˆ°è®°å¿†å†…å®¹ã€‚é€šå¸¸éœ€è¦Storeé…ç½®ä¸€ä¸ªembedæ¥æ”¯æŒè¯­ä¹‰æœç´¢ã€‚\n",
    "è®°å¿†çš„åº”ç”¨ï¼š\n",
    "â— è¯­ä¹‰è®°å¿†ï¼šå­˜å‚¨äº‹å®å’Œæ¦‚å¿µã€‚åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§æƒ…å†µï¼šProfileï¼šå°†å…³äºç”¨æˆ·ã€ç»„ç»‡æˆ–ä»£ç†è‡ªèº«çš„ç‰¹å®šä¿¡æ¯å­˜å‚¨ä¸ºä¸€ä¸ªæŒç»­æ›´æ–°çš„JSONæ–‡æ¡£ï¼Œéœ€è¦æ¨¡å‹æ¥ç”Ÿæˆæ–°çš„Profileæˆ–æ›´æ–°å·²æœ‰JSONæ¡£æ¡ˆï¼›Collectionï¼šå°†è®°å¿†å­˜å‚¨ä¸ºä¸€ç»„ç‹¬ç«‹çš„æ–‡æ¡£ï¼Œæ˜“äºç”Ÿæˆï¼Œä½†æ£€ç´¢å’Œæ›´æ–°è¾ƒä¸ºå¤æ‚ï¼Œä¸”å¯èƒ½éš¾ä»¥æ•è·è®°å¿†é—´çš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚åœ¨åº”ç”¨æ—¶ï¼Œå¯ä»¥å°†æ£€ç´¢åˆ°çš„è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æˆ–ç³»ç»ŸæŒ‡ä»¤çš„ä¸€éƒ¨åˆ†ä¼ é€’ç»™LLMï¼Œç”¨äºä¸ªæ€§åŒ–å“åº”å’Œå›ç­”äº‹å®æ€§é—®é¢˜ã€‚\n",
    "â— æƒ…æ™¯è®°å¿†ï¼šå­˜å‚¨è¿‡å»çš„äº‹ä»¶æˆ–è¡Œä¸ºç»éªŒã€‚é€šå¸¸é€šè¿‡few-shot example promptæ¥å®ç°ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹å®Œæˆä»»åŠ¡ã€‚\n",
    "â— ç¨‹åºè®°å¿†ï¼šå­˜å‚¨æ‰§è¡Œä»»åŠ¡çš„è§„åˆ™æˆ–æŒ‡ä»¤ã€‚é€šå¸¸é€šè¿‡ä¿®æ”¹ä»£ç è‡ªèº«çš„promptæ¥å®ç°ï¼Œå°†å…¶åº”ç”¨äºLLMã€‚\n",
    "InMemoryStore\n",
    "\n",
    "ä¸Checkpointerç±»ä¼¼ï¼ŒInMemoryStoreç”¨äºå¿«é€Ÿå¼€å‘å’ŒåŸå‹éªŒè¯ã€‚å®ƒå°†æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3833e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='å¸®æˆ‘æŸ¥æ‰¾é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯', additional_kwargs={}, response_metadata={}, id='1f3a2201-9b56-4084-9ac9-211f039bf87e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DkywsciacCOBvcLmAJG579bc', 'function': {'arguments': '{}', 'name': 'get_user_info', 'parameters': None}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 63, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-21751cac-9477-4807-8ccc-6f75d3bb4484-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'call_DkywsciacCOBvcLmAJG579bc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 12, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'name': 'ada', 'language': 'ä¸­æ–‡'}\", name='get_user_info', id='36ac949a-f694-4453-8cdd-b0b2350c8633', tool_call_id='call_DkywsciacCOBvcLmAJG579bc'), AIMessage(content='æˆ‘æŸ¥æ‰¾åˆ°é•¿æœŸè®°å¿†ä¸­çš„ç”¨æˆ·ä¿¡æ¯å¦‚ä¸‹ï¼š\\n\\n- ç”¨æˆ·åï¼šAda\\n- ä½¿ç”¨è¯­è¨€ï¼šä¸­æ–‡', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 95, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None}, id='run-225a580c-0755-4440-9678-54b2bb5d70ee-0', usage_metadata={'input_tokens': 95, 'output_tokens': 24, 'total_tokens': 119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.config import get_store\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "store = InMemoryStore()\n",
    "BASE_URL=\"https://api.apiyi.com/v1\"\n",
    "TOKEN=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\"\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "store.put(\n",
    "    (\"users\",),                         # å‘½åç©ºé—´ï¼šå…ƒç»„ç±»å‹ï¼Œç±»æ¯”æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶å¤¹ï¼Œæ”¯æŒåˆ†å±‚ç»„ç»‡ç»“æ„\n",
    "    \"user_123\",                         # é”®: å­—ç¬¦ä¸²ï¼Œæ˜¯å‘½åç©ºé—´å†…çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä¸€èˆ¬æ¨èä½¿ç”¨uuidåº“ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦\n",
    "    {\"name\": \"ada\", \"language\": \"ä¸­æ–‡\"}  # å€¼ï¼šPythonå­—å…¸ç±»å‹ï¼Œæ¯”å¦‚ä¿å­˜å…¬å…±è§’è‰²èµ„æ–™æ—¶å¯ä»¥æ˜¯åŒ…å«å§“åã€åå¥½ç­‰é”®å€¼å¯¹çš„å­—å…¸\n",
    ")\n",
    "\n",
    "def get_user_info(config: RunnableConfig) -> str:\n",
    "    \"\"\"æŸ¥æ‰¾ç”¨æˆ·ä¿¡æ¯çš„å‡½æ•°ï¼Œå¯ä»¥æŸ¥çœ‹é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    store = get_store()  # è·å–ä¸Šä¸‹æ–‡ä¸­å¯ç”¨çš„storeå®ä¾‹\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    user_info = store.get((\"users\",), user_id)  # è¾“å…¥å‘½åç©ºé—´å’Œé”®è¿›è¡Œç²¾ç¡®æŸ¥è¯¢\n",
    "    return str(user_info.value) if user_info else\"Unknown user\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    # ä¼ å…¥store\n",
    "    store=store\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¸®æˆ‘æŸ¥æ‰¾é•¿æœŸè®°å¿†ä¸­å‚¨å­˜çš„ç”¨æˆ·ä¿¡æ¯\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"user_123\"}}\n",
    ")\n",
    "\n",
    "print(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccd4f3",
   "metadata": {},
   "source": [
    "## æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨\n",
    "\n",
    "ä¸ºäº†è®©è®°å¿†çœŸæ­£â€é•¿æœŸâ€œï¼Œç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨æ•°æ®åº“æ”¯æŒçš„Storeï¼ŒLangGraphç›®å‰ä¸»è¦æ”¯æŒPostgresStoreå’ŒRedisStoreã€‚æˆ‘ä»¬ä»¥PostgresStoreä¸ºä¾‹æ¥è¿›è¡Œè¯´æ˜ã€‚\\\n",
    "æ¥ä¸‹æ¥è¿›è¡Œç¤ºä¾‹è¯´æ˜ã€‚æ•´ä½“è¿‡ç¨‹ä¸Checkpointerç±»ä¼¼ï¼Œå…³é”®åŒºåˆ«åœ¨äºStoreæ˜¯æ€æ ·åœ¨èŠ‚ç‚¹å†…éƒ¨è¢«è®¿é—®å’Œä½¿ç”¨çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87946df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "BASE_URL=\"https://api.apiyi.com/v1\"\n",
    "TOKEN=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\"\n",
    "MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=\"openai\", \n",
    "    base_url=BASE_URL,\n",
    "    api_key=TOKEN,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "DB_URI = \"postgresql://postgres:password@localhost:5432/agent-memory?sslmode=disable\"\n",
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    store.setup()  # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¿…é¡»è¦setup()\n",
    "#checkpointer.setup()\n",
    "    \n",
    "# å£°æ˜storeå‚æ•°\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig, \n",
    "    *,\n",
    "    store: BaseStore,  # åœ¨èŠ‚ç‚¹ä¸­è®¿é—®storeçš„æ ‡å‡†æ–¹å¼ï¼Œéœ€è¦åœ¨å‡½æ•°ç­¾åä¸Šï¼ŒåŠ ä¸€ä¸ªstore\n",
    "    ):\n",
    "    # ä»storeä¸­è¯»å–è®°å¿†\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "    system_msg = f\"ä½ æ˜¯ä¸€ä¸ªä¸äººç±»äº¤æµçš„å°åŠ©æ‰‹ï¼Œç”¨æˆ·ä¿¡æ¯: {info}\"\n",
    "\n",
    "    # å‘storeä¸­å†™å…¥è®°å¿†\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"è®°ä½\" in last_message.content.lower(): memory = \"ç”¨æˆ·åå­—æ˜¯ada\"\n",
    "    store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "    response = model.invoke([{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "    \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer, store=store)  # agentåŒæ—¶é…å¤‡äº†çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†èƒ½åŠ›\n",
    "    \n",
    "# ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œå‘Šè¯‰agentç”¨æˆ·çš„åå­—\n",
    "config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"1\"}}\n",
    "\n",
    "response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«adaï¼è®°ä½è¿™ä¸ªåå­—å‘¦~\"}]}, config)\n",
    "\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# ç¬¬äºŒæ¬¡å¯¹è¯ï¼Œæ–°çº¿ç¨‹ï¼Œè¯¢é—®agentè®°ä¸è®°å¾—ç”¨æˆ·çš„åå­—\n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": \"1\"}}\n",
    "\n",
    "response = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆ?\"}]}, config)\n",
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
